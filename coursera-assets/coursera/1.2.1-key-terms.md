# Key Terms

**DLT Expectations**: DLT expectations are declarative data quality constraints applied directly to table definitions within a Delta Live Tables pipeline. They allow engineers to define validation rules as first-class pipeline components, with violations tracked automatically and surfaced in the pipeline user interface (UI) for monitoring.

**EXPECT Constraint**: The EXPECT constraint is the default expectation enforcement mode in DLT that logs a warning when a row violates the specified condition but still allows the row to pass through to the target table. This mode is useful during development or when data quality issues should be monitored without blocking downstream processing.

**EXPECT OR DROP**: EXPECT OR DROP is an expectation enforcement mode that silently removes any rows that violate the specified constraint before they are written to the target table. This mode is appropriate when bad data should be filtered out automatically, such as dropping records with null keys or out-of-range values.

**EXPECT OR FAIL**: EXPECT OR FAIL is the strictest expectation enforcement mode, which halts the entire pipeline execution immediately when any row violates the constraint. This mode is used for critical data quality rules where even a single invalid record indicates a serious upstream problem that must be resolved before processing continues.

**Data Quality Metrics**: Data quality metrics in DLT are automatically collected statistics about expectation violations, including the number of records that passed, failed, or were dropped for each defined constraint. These metrics are visible in the pipeline UI event log and can be used to set up alerts, track quality trends, and audit data reliability over time.

## References

- [Shankar et al., "Moving Fast With Broken Data," arXiv:2303.06094, 2023](https://arxiv.org/abs/2303.06094)
- [Zhou et al., "A Survey on Data Quality Dimensions and Tools for Machine Learning," arXiv:2406.19614, 2024](https://arxiv.org/abs/2406.19614)
